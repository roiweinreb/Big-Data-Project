method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 100, by = 1))
)
knn_results_ordOut <- knn_reg_model_ordOut$results
#min RMSE's index
min_rmse_indx_ordOut <- which.min(knn_results$RMSE)
rmse_knn_ordOut <- round(knn_results_ordOut$RMSE[min_rmse_indx_ordOut],4)
rmse_knn_ordOut
set.seed(1)
knn_reg_model_reg = train( #Regsubsets Features with G1 G2
G3 ~ absences + reason + Fjob + guardian + activities + G2
+ traveltime + studytime + failures + famrel + G1 ,
data = math_train_modified,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 100, by = 1))
)
knn_results_reg <- knn_reg_model_reg$results
#min RMSE's index
min_rmse_indx_reg <- which.min(knn_results_reg$RMSE)
rmse_knn_reg <- round(knn_results_reg$RMSE[min_rmse_indx_reg],4)
p_label_reg <- paste('(',knn_results_reg$k[min_rmse_indx_reg],',',
rmse_knn_reg,')',sep = '')
#K-nn regression without G1 G2
#-----------------------------
set.seed(1)
knn_reg_model_reg_Gout = train( #Regsubsets Features without G1 G2
G3 ~ sex + age + famsize + Medu + Mjob + Fjob + reason + failures + schoolsup + famsup + paid + higher + romantic + freetime + goout + health + absences,
data = math_train_mod_Gout,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 100, by = 1))
)
knn_results_reg_Gout <- knn_reg_model_reg_Gout$results
#min RMSE's index
min_rmse_indx_reg_Gout <- which.min(knn_results_reg_Gout$RMSE)
rmse_knn_reg_Gout <- round(knn_results_reg_Gout$RMSE[min_rmse_indx_reg_Gout],4)
#plot rmse vs k
obj2 <- ggplot(data = knn_results_reg,mapping = aes(x = k,y = RMSE)) + geom_line()
obj2 + geom_point(data=knn_results_reg,aes(x = k[min_rmse_indx_reg],y = RMSE[min_rmse_indx_reg]),color="red",size=4) +
geom_text(data=knn_results_reg, mapping = aes(x = k[min_rmse_indx_reg],
y =  RMSE[min_rmse_indx_reg],label=p_label_reg),hjust=-0.2, vjust=0.32) +
ggtitle('RMSE vs k') + theme(plot.title = element_text(hjust = 0.5))
#TEST RMSE
#Function which calculates RMSE
calc_RMSE = function(actual, predicted) {
sqrt(mean((actual-predicted)^2))
}
#RMSE for regsubsets lm model with G1 G2
rmse_test_reg <- round(calc_RMSE(math_test_modified$G3,predict(model_lr_regsubsets,newdata=math_test_modified)),5)
#RMSE for regsubsets lm model without G1 G2
rmse_test_reg_Gout <- round(calc_RMSE(math_test_mod_Gout$G3,predict(model_lr_reg_Gout,newdata=math_test_mod_Gout)),5)
#RMSE for boxcox model with G1 G2
y=pmax(predict(boxcox_model_regsubsets,newdata=math_test_modified),0)
y=((lambda*y+1)^(1/lambda))-1
rmse_test_boxcox <- round(calc_RMSE(math_test_modified$G3,y),5)
#RMSE for boxcox model without G1 G2
y=pmax(predict(boxcox_model_reg_Gout,newdata=math_test_mod_Gout),0)
y=((lambda_Gout*y+1)^(1/lambda_Gout))-1
rmse_test_boxcox_Gout <- round(calc_RMSE(math_test_mod_Gout$G3,y),5)
#RMSE for knn lm model with G1 G2
rmse_test_knn <- round(calc_RMSE(math_test$G3,predict(knn_reg_model_reg,newdata=math_test)),5)
#RMSE for regsubsets lm model without G1 G2
rmse_test_knn_Gout <- round(calc_RMSE(math_test$G3,predict(knn_reg_model_reg_Gout,newdata=math_test)),5)
math_regression_best_G_KNN_train <- rmse_knn_reg
math_regression_best_NoG_KNN_train <- rmse_knn_reg_Gout
math_regression_best_G_KNN_test <- rmse_test_knn
math_regression_best_NoG_KNN_test <- rmse_test_knn_Gout
r_names <- c('Regsubsets*','Regsubsets**','Boxcox*','Boxcox**','KNN*','KNN**')
RMSE <- c(rmse_regsubsets,rmse_reg_Gout,rmse_boxcox,rmse_boxcox_Gout,rmse_knn_reg,rmse_knn_reg_Gout)
AdjR2<- c(as.character(adjr2_regsubsets),as.character(adjr2_reg_Gout),as.character(adjr2_boxcox),as.character(adjr2_boxcox_Gout),'-','-')
Shapiro <- c(as.character(shapiro_regsubsets),as.character(shapiro_reg_Gout),as.character(shapiro_boxcox),as.character(shapiro_boxcox_Gout),'-','-')
BP <- c(as.character(bp_regsubsets),as.character(bp_reg_Gout),as.character(bp_boxcox),as.character(bp_boxcox_Gout),'-','-')
Test_RMSE <- c(rmse_test_reg,rmse_test_reg_Gout,rmse_test_boxcox,rmse_test_boxcox_Gout,rmse_test_knn,rmse_test_knn_Gout)
summary_data <- data.frame(RMSE,AdjR2,Shapiro,BP,Test_RMSE,row.names = r_names)
kable(summary_data,digits = c(4,4,19,7))  %>%
kable_styling()
#Modify data to include 0/'not zero' in G3
math_train_zero <- math_train
math_train_zero$G3[which(math_train_zero$G3>0)] <- "not zero"
math_test_zero <- math_test
math_test_zero$G3[which(math_test_zero$G3>0)] <- "not zero"
#train classifier
set.seed(1)
knn_class_zero = train( #Regsubsets Features with G1 G2
form = G3 ~ .,
data = math_train_zero,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 100, by = 1))
)
best_acc_idx <- which.max(knn_class_zero$results$Accuracy)
acc_knn_train <- max(knn_class_zero$results$Accuracy)
acc_knn_train
k_knn_train <- knn_class_zero$results$k[best_acc_idx]
k_knn_train
#create dataset without zero
math_train_zout <- math_train[which(math_train$G3 != 0),]
#Regsubsets with G1,G2
subsets_zout <- regsubsets(G3 ~ . ,data = math_train_zout, nvmax = 20)
subsets_zout_sum <- summary(subsets_zout)
#get index of best adjr2
best_adjr2_zout <- which.max(subsets_zout_sum$adjr2)
#get best adjr2's value
subsets_zout_sum$adjr2[best_adjr2_zout]
#get coef values of the chosen model
coef(subsets_zout,best_adjr2_zout)
#modified train data (with zero)
math_train_class_reg_mod=math_train
math_train_class_reg_mod$Mjob[math_train_class_reg_mod$Mjob !='other'] <- 'teacher'
math_train_class_reg_mod$Fjob[math_train_class_reg_mod$Fjob !='health' & math_train_class_reg_mod$Fjob !='other' & math_train_class_reg_mod$Fjob !='teacher'] <- 'services'
math_train_class_reg_mod$reason[math_train_class_reg_mod$reason!='home'] <- 'other'
math_train_class_reg_mod$guardian[math_train_class_reg_mod$guardian!='other'] <- 'mother'
#modified test data (with zero)
math_test_class_reg_mod=math_test
math_test_class_reg_mod$Mjob[math_test_class_reg_mod$Mjob !='other'] <- 'teacher'
math_test_class_reg_mod$Fjob[math_test_class_reg_mod$Fjob !='health' & math_test_class_reg_mod$Fjob !='other' & math_test_class_reg_mod$Fjob !='teacher'] <- 'services'
math_test_class_reg_mod$reason[math_test_class_reg_mod$reason!='home'] <- 'other'
math_test_class_reg_mod$guardian[math_test_class_reg_mod$guardian!='other'] <- 'mother'
#modify train
math_train_zout_mod=math_train_zout
math_train_zout_mod$Mjob[math_train_zout_mod$Mjob !='other'] <- 'teacher'
math_train_zout_mod$Fjob[math_train_zout_mod$Fjob !='health' & math_train_zout_mod$Fjob !='other' & math_train_zout_mod$Fjob !='teacher'] <- 'services'
math_train_zout_mod$reason[math_train_zout_mod$reason!='home'] <- 'other'
math_train_zout_mod$guardian[math_train_zout_mod$guardian!='other'] <- 'mother'
#modify test
math_test_zout <- math_test[which(math_test$G3 != 0),]
math_test_zout_mod=math_test_zout
math_test_zout_mod$Mjob[math_test_zout_mod$Mjob !='other'] <- 'teacher'
math_test_zout_mod$Fjob[math_test_zout_mod$Fjob !='health' & math_test_zout_mod$Fjob !='other' & math_test_zout_mod$Fjob !='teacher'] <- 'services'
math_test_zout_mod$reason[math_test_zout_mod$reason!='home'] <- 'other'
math_test_zout_mod$guardian[math_test_zout_mod$guardian!='other'] <- 'mother' <- 'other'
#lm regsubsets zout with G1,G2
reg_zout <- lm(G3 ~ address + Mjob + Fjob + guardian + reason + G2
+ schoolsup + paid + nursery + famrel + G1 + goout + health ,data = math_train_zout_mod)
reg_zout_sum <- summary(reg_zout)
#RMSE
rmse_reg_zout <- round(reg_zout_sum$sigma,4)
#adjr2
adjr2_reg_zout <- round(reg_zout_sum$adj.r.squared,4)
#Shapiro-Wilk
shapiro_reg_zout <- round(shapiro.test(resid(reg_zout))$p.value,20)
#Breusch-Pagan
bp_reg_zout <- round(bptest(reg_zout)$p.value,8)
#QQplot
par(mfrow = c(1,2))
qqnorm(resid(reg_zout),col = 'grey',ylab =  'Residuals Quantiles')
qqline(resid(reg_zout),col = 'darkorange')
#residuals vs fitted
plot(fitted(reg_zout),resid(reg_zout),xlab =  'Fitted', ylab = 'Residuals',col = 'grey', main = 'Residuals vs Fitted Plot')
abline(h = 0, col = 'darkorange')
set.seed(1)
#rmse train classifier
rmse_knn_class_train1 <- sum(math_train$G3[fitted(knn_class_zero) == 0] ^ 2)
#rmse train linear reg
rmse_reg_train2 <- sum((predict(reg_zout,newdata=math_train_class_reg_mod)[fitted(knn_class_zero) != 0] - math_train_class_reg_mod$G3[fitted(knn_class_zero) != 0]) ^ 2)
#total train rmse
rmse_train_class_reg <- sqrt((rmse_knn_class_train1+rmse_reg_train2)/nrow(math_train))
rmse_train_class_reg
set.seed(1)
#predictions
knn_class_zero_fit <- predict(knn_class_zero,newdata = math_test_zero)
reg_zout_fit <- predict(reg_zout,newdata=math_test_class_reg_mod[knn_class_zero_fit != 0,])
#accuracy calculation function
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
#classifier accuracy
acc_knn_test <- calc_acc(math_test_zero$G3,knn_class_zero_fit)
acc_knn_test
#rmse test classifier
rmse_knn_class_test1 <- sum(math_test$G3[knn_class_zero_fit == 0] ^ 2)
rmse_knn_class_test1
#rmse test linear reg
rmse_reg_test2 <- sum((reg_zout_fit - math_test$G3[knn_class_zero_fit != 0]) ^ 2)
#total test rmse
rmse_test_class_reg <- sqrt((rmse_knn_class_test1+rmse_reg_test2)/nrow(math_test))
rmse_test_class_reg
#all test data that classifier predicted as != 0
class_not_zero <- math_test_class_reg_mod[knn_class_zero_fit != 0,]
#predictions of linear reg where classifier predicted != 0 but actual is zero
reg_zout_fit[class_not_zero$G3 == 0]
#Classification of 4 categories
G3_4Class <- vector('numeric',nrow(dat_mat))
# grades 0-5
G3_4Class[which(dat_mat$G3<=5)] <- 'D'
# grades 6-10
G3_4Class[which(dat_mat$G3>5 & dat_mat$G3<=10)] <- 'C'
# grades 11-15
G3_4Class[which(dat_mat$G3>10 & dat_mat$G3<=15)] <- 'B'
# grades 16-20
G3_4Class[which(dat_mat$G3>15 & dat_mat$G3<=20)] <- 'A'
math_Class <- cbind(dat_mat[,-33],G3Class=G3_4Class)
kable(head(math_Class))  %>%
kable_styling() %>%  scroll_box(width = "800px", height = "180px")
#Data partition
set.seed(3)
train_idx_class <- createDataPartition(math_Class$G3Class, p = 0.8, list = FALSE)
math_train_Class <- math_Class[train_idx_class,]
math_test_Class <- math_Class[-train_idx_class,]
#get count for each class
classes_table <- table(math_train_Class$G3Class)
#calculate B class percentage
B_perc <- round(classes_table[[2]] / nrow(math_train_Class) * 100,2)
#percentage
histogram(math_train_Class$G3Class,frequency = TRUE,main = paste('Percentage of B grade is',B_perc),xlab = 'Grades')
#With G1 G2
#-----------
#modify train
math_train_Class_modified=math_train_Class
math_train_Class_modified$Fjob[math_train_Class_modified$Fjob!='health' &
math_train_Class_modified$Fjob!='services'] <- 'other'
math_train_Class_modified$reason[math_train_Class_modified$reason!='home'] <- 'other'
math_train_Class_modified$guardian[math_train_Class_modified$guardian!='mother'] <- 'other'
#modify test
math_test_Class_modified=math_test_Class
math_test_Class_modified$Fjob[math_test_Class_modified$Fjob!='health' &
math_test_Class_modified$Fjob!='services'] <- 'other'
math_test_Class_modified$reason[math_test_Class_modified$reason!='home'] <- 'other'
math_test_Class_modified$guardian[math_test_Class_modified$guardian!='mother'] <- 'other'
#without G1 G2
#--------------
#data modification train
math_train_Class_mod_Gout=math_train_Class
math_train_Class_mod_Gout$Mjob[math_train_Class_mod_Gout$Mjob !='teacher'] <- 'other'
math_train_Class_mod_Gout$reason[math_train_Class_mod_Gout$reason !='other' & math_train_Class_mod_Gout$reason !='reputation' ] <- 'home'
#data modification test
math_test_Class_mod_Gout=math_test_Class
math_test_Class_mod_Gout$Mjob[math_test_Class_mod_Gout$Mjob !='teacher'] <- 'other'
math_test_Class_mod_Gout$reason[math_test_Class_mod_Gout$reason !='other' & math_test_Class_mod_Gout$reason !='reputation'] <- 'home'
#with G1 G2
#--------------
#K-NN Regsubsets features
set.seed(1)
knn_class_model_reg <- train(
form = G3Class ~ absences + reason + Fjob + guardian + activities + G2
+ traveltime + studytime + failures + famrel + G1,
data = math_train_Class_modified,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
#knn_class_model
knn_results_Class <- knn_class_model_reg$results
#max Accuracy's index
max_Accuracy_indx <- which.max(knn_results_Class$Accuracy)
Accuracy_knn <- round(knn_results_Class$Accuracy[max_Accuracy_indx],3)
p_label_C <- paste('(',knn_results_Class$k[max_Accuracy_indx],',',
Accuracy_knn,')',sep = '')
#plot rmse vs k
objKnn <- ggplot(data = knn_results_Class,mapping = aes(x = k,y = Accuracy)) + geom_line() + geom_point(data=knn_results_Class,aes(x = k[max_Accuracy_indx],y = Accuracy_knn),color="red",size=4) +
geom_text(data=knn_results_Class, mapping = aes(x = k[max_Accuracy_indx],
y =  Accuracy_knn,label=p_label_C),hjust=-0.2, vjust=0.32) +
ggtitle('Accuracy vs k') + theme(plot.title = element_text(hjust = 0.5))
#CM
set.seed(1)
predTest <- predict(knn_class_model_reg, newdata = math_test_Class_modified)
confusion_matrix_rf <- as.data.frame(table(predTest, math_test_Class$G3Class))
obj2 <- ggplot(data = confusion_matrix_rf,
mapping = aes(x = predTest,
y = Var2)) +
geom_tile(aes(fill = Freq)) + xlab('Predicted Class') + ylab('Actual Class') + ggtitle('Confusion Matrix') + theme(plot.title = element_text(hjust = 0.5)) +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "grey",
high = "red",
guide = "legend")
grid.arrange(objKnn,obj2,nrow = 1, ncol = 2)
knn_class_model_reg_Acc_Test <- calc_acc(actual = math_test_Class$G3Class, predicted = predTest)
knn_class_model_reg_Acc_Test
#All three models of K-NN
#with G1 G2
#--------------
#K-NN Regsubsets features
set.seed(1)
knn_class_model_reg <- train(
form = G3Class ~ absences + reason + Fjob + guardian + activities + G2
+ traveltime + studytime + failures + famrel + G1,
data = math_train_Class_modified,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
knn_class_model_reg_Acc_Train <- max(knn_class_model_reg$results$Accuracy)
#K-NN All features
set.seed(1)
knn_class_model <- train(
form = G3Class ~ .,
data = math_train_Class,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
#knn_class_model
knn_class_model_Acc_Train <- max(knn_class_model$results$Accuracy)
#K-NN All Features except non ordinal categorical variables
set.seed(1)
knn_class_model_ordOut = train( #All Features except non ordinal categorical variables
G3Class ~ .,
data = math_train_Class[,-c(9:12)],
method = "knn",
trControl = trainControl(method = "cv", number = 5),
#preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 100, by = 1))
)
knn_class_model_ordOut_Acc_Train <- max(knn_class_model_ordOut$results$Accuracy)
#K-NN No G
#All Features
set.seed(1)
knn_class_model_NoG <- train(
form = G3Class ~ . -G1 -G2,
data = math_train_Class,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
#knn_class_model_NoG
knn_class_model_NoG_Acc_Train <- max(knn_class_model_NoG$results$Accuracy)
knn_class_model_NoG_Acc_Test <- calc_acc(actual = math_test_Class$G3Class,
predicted = predict(knn_class_model_NoG, newdata = math_test_Class))
#All Features except non ordinal categorical variables
set.seed(1)
knn_class_model_NoG_ordOut <- train(
form = G3Class ~ . -G1 -G2,
data = math_train_Class[,-c(9:12)],
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
#knn_class_model_NoG
knn_class_model_NoG_ordOut_Acc_Train <- max(knn_class_model_NoG_ordOut$results$Accuracy)
knn_class_model_NoG_ordOut_Acc_Test <- calc_acc(actual = math_test_Class$G3Class,
predicted = predict(knn_class_model_NoG_ordOut, newdata = math_test_Class))
#regsubsets features
set.seed(1)
knn_class_model_NoG_reg <- train(
form = G3Class ~ absences + reason + Fjob + guardian + activities + traveltime + studytime + failures + famrel,
data = math_train_Class_mod_Gout,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "knn",
tuneGrid = expand.grid(k = seq(3, 100, by = 1)))
#knn_class_model_NoG
knn_class_model_NoG_reg_Acc_Train <- max(knn_class_model_NoG_reg$results$Accuracy)
knn_class_model_NoG_reg_Acc_Test <- calc_acc(actual = math_test_Class$G3Class,
predicted = predict(knn_class_model_NoG_reg, newdata = math_test_Class_mod_Gout))
#regsubsets features
set.seed(1)
rf_class_model_reg <- train(
form = G3Class ~ absences + reason + Fjob + guardian + activities + G2
+ traveltime + studytime + failures + famrel + G1,
data = math_train_Class_modified,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "ranger")
rf_accuracy <- round(max(rf_class_model_reg$results$Accuracy),5)
#regsubsets features
set.seed(1)
rf_class_model_reg <- train(
form = G3Class ~ absences + reason + Fjob + guardian + activities + G2
+ traveltime + studytime + failures + famrel + G1,
data = math_train_Class_modified,
trControl = trainControl(method = "cv", number = 5, savePredictions = T),
method = "ranger")
rf_accuracy <- round(max(rf_class_model_reg$results$Accuracy),5)
cars
x<-Boston
View(x)
?merge
mutual <- merge(dat_mat, dat_por, by = c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
View(mutual)
obj <- ggplot(data=mutual, aes(G3.x-G3.y))
o
obj <- ggplot(data=mutual, aes(G3.x-G3.y))
obj
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..))
obj
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'orange')
obj
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white')
obj
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white') + geom_density()
obj
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white') + geom_density(col = "red")
obj
?createDataPartition
train_idx <- createDataPartition(dat_mat$G3, p=0.8, list=TRUE)
mat_train <- dat_mat[train_idx,]
mat_test <- dat_mat[-train_idx,]
train_idx <- createDataPartition(dat_mat$G3, p=0.8, list=FALSE)
mat_train <- dat_mat[train_idx,]
mat_test <- dat_mat[-train_idx,]
dat_mat <- read.csv("student-mat.csv",sep = ';')
dat_por <- read.csv("student-por.csv",sep = ';')
mutual <- merge(dat_mat, dat_por, by = c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white') + geom_density(col = "red")
obj
set.seed(1)
train_idx <- createDataPartition(dat_mat$G3, p=0.8, list=FALSE)
mat_train <- dat_mat[train_idx,]
mat_test <- dat_mat[-train_idx,]
dat_mat <- read.csv("student-mat.csv",sep = ';')
dat_por <- read.csv("student-por.csv",sep = ';')
mutual <- merge(dat_mat, dat_por, by = c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white') + geom_density(col = "red")
obj
set.seed(1)
train_idx <- createDataPartition(dat_mat$G3, p=0.8, list=FALSE)
mat_train <- dat_mat[train_idx,]
mat_test <- dat_mat[-train_idx,]
setwd("C:/Users/roinr/Desktop/Big_Data_Project")
dat_mat <- read.csv("student-mat.csv",sep = ';')
dat_por <- read.csv("student-por.csv",sep = ';')
mutual <- merge(dat_mat, dat_por, by = c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
obj <- ggplot(data=mutual, aes(G3.x-G3.y)) + geom_histogram(aes(y=..density..), bins = 10, col = 'white') + geom_density(col = "red")
obj
set.seed(1)
train_idx <- createDataPartition(dat_mat$G3, p=0.8, list=FALSE)
mat_train <- dat_mat[train_idx,]
mat_test <- dat_mat[-train_idx,]
subset(math_train, select = -c(Fjob, Mjob,reason,guardian))
#finding strong correlations between response to predictors
cor(mat_train, method = c("pearson", "kendall", "spearman"))
#finding strong correlations between response to predictors
cor(as.numeric(mat_train), method = c("pearson", "kendall", "spearman"))
math_train_corr <- subset(math_train, select = -c(Fjob, Mjob,reason,guardian))
sapply(math_train_corr, is.factor)
#finding strong correlations between response to predictors
idx <- sapply(mat_train, is.factor)
idx <- sapply(mat_train, is.factor)
mat_train_cor <- lapply(mat_train[idx], function(x) as.numeric(x)-1)
View(mat_train_cor)
rank(mat_train$school)
?rank
sapply(mat_train, is.factor)
math_train_corr <- subset(math_train, select = -c(Fjob, Mjob,reason,guardian))
inds <- sapply(math_train_corr, is.factor)
lapply(math_train_corr[inds], function(x) as.numeric(as.factor(x)) - 1)
math_train_corr <- subset(math_train, select = -c(Fjob, Mjob,reason,guardian))
inds <- sapply(math_train_corr, is.factor)
lapply(math_train_corr[inds], function(x) as.numeric(as.factor(x)) - 1)
mat_train_cor <- mat_train
inds <- sapply(mat_train_cor, is.factor)
sapply(mat_train_cor, is.factor)
lapply(mat_train_cor[inds], function(x) as.numeric(as.factor(x)) - 1)
cor_mat <- round(cor(math_train_corr),2)
cor_mat <- round(cor(mat_train_cor),2)
mat_train_cor[inds] <- lapply(mat_train_cor[inds], function(x) as.numeric(as.factor(x)) - 1)
cor_mat <- round(cor(mat_train_cor),2)
round(cor(mat_train_cor),2)
library(reshape2)
melt(cor_mat)
cor_mat <- round(cor(mat_train_cor),2)
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cor_mat)
upper_tri <- get_upper_tri(cor_mat)
melted_cormat <- melt(upper_tri, na.rm = TRUE)
obj1 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
obj1
obj1 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1))
obj1
obj1 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
obj1
obj1 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 0,
size = 12, hjust = 1))+
coord_fixed()
obj1
library(ggplot2)
obj1 <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5,
size = 12, hjust = 1))+
coord_fixed()
obj1
